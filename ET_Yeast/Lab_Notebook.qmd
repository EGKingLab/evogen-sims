---
title: "Lab_Notebook"
author: "Esdras T"
format: html
editor: visual
---

## Simulation project

Here are the notes taken while working on the yeast simulation model. Most of these notes are based on code writing and some additional ideas that might come up while working on the project.

## Writing Flow

The most current notes are at the top.

[***June 8th 2023***]{.underline}

Now that I have modeled Selection with changing generations & optimum based on standard deviations, I should now think of modeling irregular periodicity (how many generations the optimum should change) or how much the environment should affect the optimum (1sd, 2sd, or even a different number following a given distribution).

[***June 5th 2023***]{.underline}

Running constant and fluctuating selection while considering 100 loci, different selection strength (Optimum having some standard deviations from mean phenotypes), and several levels of intervals.

Standard deviation: 1, 2, 3, and 4

Levels of interval: 10, 20, and 30.

The names of output files having r*eplicate number, loci numbers, heritability value, standard deviations, and generation intervals*. For example: genome5_100_H0.5SD2Gen20.csv

[***June 4th 2023***]{.underline}

Here are some of the fitness functions to try. The 3rd and 4th functions are pretty much the same and they work very well for scaled phenotype. They are also considered as a strong selection while the 2nd function is a weak selection. The 5th function work with non-scaled phenotypes. The first and last functions might need to be modified.

1.  inds.fitnessScaling = 1 + dnorm(newopt-phenotypes,0,0.25);
2.  inds.fitnessScaling = 1-(abs(phenotypes - newopt\[sim.cycle\])/200);
3.  inds.fitnessScaling = exp(-(0.02) \* (phenotypes - newopt\[sim.cycle\])\^2);
4.  **inds.fitnessScaling = exp(-(1/(phenotypes)) \* (phenotypes - newopt\[sim.cycle\])\^2);**
5.  inds.fitnessScaling = exp(-(1/mean(phenotypes)\^2) \* (phenotypes - newopt\[sim.cycle\])\^2); //# This fitness goes with unscaled phenotype
6.  1.0 + dnorm(100 - phenotypes, 0.0, 5.0);

[***May 30th 2023***]{.underline}

The peak frequency can indicate where there is the highest power (spectral density), and that would lead us to how many cycles (signal) are in our dataset (1/peak frequency). The total number of periods divided by the number of cycles will tell us when the signal comes back.

Note that MCMC sampling can be used to validate our peaks. (Review your notes)

[***May 23rd 2023***]{.underline}

Have been working with FFT. I have figured out that the best way to work with them for each QTL position is to use a for loop or a function (Check your current code). While I am still processing data on every QTL along all generations, it would instead be feasible to do the analysis and then find the mean Frequency for each generation. From there, we can work on the plots. Despite everything that I have done so far, I need to find the best way to post-processing for Fourier. Also, I need to check if all Fourier assumptions are met otherwise I would consider wavelet assumptions. One of the assumptions of Fourier is "The sampled signal segment must contain a whole number of [periods](https://www.nti-audio.com/en/support/know-how/fast-fourier-transform-fft#:~:text=In%20the%20Fourier%20transformation%2C%20the%20assumption%20is%20that,segment%20must%20contain%20a%20whole%20number%20of%20periods.). (Does this means that a QTL has to be present for all generations?????)"

[***March 6th 2023***]{.underline}

Started the project while following a single step per time. The first stem was to set the genome size and the number of QTLs. The genome size will approximately equal to 1,220,281 (arbitrary), and the number of QTLs considered are 1 with interval (I) of 610,140, 10 QTLs (I = 110,934), 70 QTLs (I = 17,186), 100 QTLs (I = 12,081), 300 QTLs (I = 4,053).

> To write the file, the file name will include the replicate, QTL#, and hertability value

On the plan, there is writing a bash code that combines all the files together.

[***February 20th 2023***]{.underline}

Remember that to output the whole genome file, you can use sim.outputFull("path to your directory"). The same applies when you want to save VCF file and some other important files.

[***January 7th 2023***]{.underline}

\[***defineGlobal***\] makes your object available for use. For example, the new optimum or new population size. ?? How is it different from define constant? For a constant, it is mostly a single number while Global can be a list.

[***January 5th 2023***]{.underline}

The tick and cycle events in Slim make sense especially when we are considering overlapping populations. That is, one person might have a child, grand-child, and grand grandkids. Therefore, for that particular person, we might see one tick, and have multiple cycles. \[That's how I would explain the tick and cycle thing\]

[***December 23rd 2022***]{.underline}

I today figured out that .tagF wouldn't work until we scale the fitness. Maybe it might be good to read more about it in the Eidos manual. Also, according to the plots, it seemed like the mutation doesn't change much about the frequency over generation when using a genome from a dummy population

[***December 5th 2022***]{.underline}

Creating an initial genome using a dummy population. In this case, we need a sub-population with a single genome that has added mutations and its effect size corresponds to the number of QTLs.

```{r, echo=FALSE}
library(slimr)
slim_block(1, early(),
             {sim.addSubpop("p2", 1);
	g = p2.genomes[0];
	muts = g.addNewMutation(m2, rexp(100), Q);
	
	sim.addSubpop("p1", 10000);
	marks = runif(100, 0,1);
	ind = 0;
	for(qpos in Q)
	{
		for(g in p1.genomes)
		{
			if(rbinom(1,1,marks[ind])==1){g.addMutations(muts[ind]);}
		}
		ind = ind + 1;
	}
	p2.setSubpopulationSize(0);})

```

Have an initial frequency distribution; draw random positions where your mutations could be in the sub-population to use.

[***November 29th 2022***]{.underline}

[*The very beginning of the notes.*]{.underline}

During the one on one meeting, we discussed about selection coefficient. I came to realize that our selection is predicated on the **optimum phenotype** not the selection coefficient we set. For fluctuating selection, we will be **changing the optimum phenotype at a given generation interval**.

Also, we talked about the introduction of new mutations. When only one individual carries the mutation (assuming beneficial mutation), that individual will have a high fitness thus higher reproductive priorities. Therefore, the mutation will fix so quickly.
